{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Graphs\n",
    "\n",
    "This tutorial demonstrates how to use widgets to interact with graphs and see the respective views in Urchin.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/VirtualBrainLab/urchin-examples/blob/main/basics/interactive_graphs.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dependencies and necessary data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Urchin\n",
    "\n",
    "Urchin is a Python package stored on PyPI, the following code needs to be run the first time you use Urchin in a Python environment. \n",
    "\n",
    "Urchin's full documentation can be found [on our website](https://virtualbrainlab.org/urchin/installation_and_use.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing urchin if running for the first time\n",
    "!pip install oursin -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oursin as urchin\n",
    "urchin.setup()\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "# To enable use on colab:\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the data:\n",
    "\n",
    "For this tutorial, we have datasets loaded onto google drive. If using your own data, be sure to reference documentation for proper formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_gdrive_npy(gdrive_url):\n",
    "    file_id = gdrive_url.split(\"/\")[-2]\n",
    "\n",
    "    # Construct the direct download link\n",
    "    download_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "    response = requests.get(download_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = np.squeeze(np.load(io.BytesIO(response.content)))\n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "\n",
    "    return data\n",
    "\n",
    "def download_csv(gdrive_url):\n",
    "    file_id = gdrive_url.split(\"/\")[-2]\n",
    "    download_link = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    response = requests.get(download_link)\n",
    "\n",
    "    df = pd.read_csv(io.StringIO(response.text))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_samp = download_gdrive_npy('https://drive.google.com/file/d/1cv0ylzlQHsjPobVMfjDzQsALKBjmhZ7L/view?usp=sharing')\n",
    "sc = download_gdrive_npy('https://drive.google.com/file/d/17ao2qgmuRMew1CIDBBdfoUY5LojdFCOu/view?usp=sharing')\n",
    "event_start = download_gdrive_npy('https://drive.google.com/file/d/1bFN-ZyOulUtbNs7WIq9SqyPbrSBaaijB/view?usp=sharing')\n",
    "event_ids = download_gdrive_npy('https://drive.google.com/file/d/1n4smr91u-n8NXzqt6HO9CN13we_13rhR/view?usp=sharing')\n",
    "locations = download_csv('https://drive.google.com/file/d/1b9LDBELDmijduN1pjnfjlylH8cYuFQW2/view?usp=sharing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using graphing objects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a graph object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_graph = urchin.ui.interactive_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attatching the data to the graph object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_graph.avg_and_bin(st_samp, sc, event_start, event_ids, window_start_sec=0.1, event_duration_sec = 0.3, window_end_sec=0.2, sample= True)\n",
    "neuron_graph.avg_data = np.delete(neuron_graph.avg_data, 88, axis=0) #This line is specific for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Displaying a graph of activity from one neuron across all stimuli:\n",
    "\n",
    "Note: since these graphs are from the same object, if you are coming back to this graph after running the stimulus view function, simply re-run this function to regain interactivity control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_graph.plot_neuron_view_interactive_graph()\n",
    "# for this dataset, start by checking out neuron 354 to see interesting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying a graph of neural activity for for each stimuli:\n",
    "\n",
    "Note: This uses randomly generated colors but if you want to set custom colors for the graph without generating neurons in a brainview, you can set `neuron_graph.neuron_colors=[list of colors of length of # neurons]` outside of this function, and `neuron_graph.neuron_colors = None` if trying to go back to random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_graph.plot_stim_view_interactive_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incoorporating Urchin component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urchin.ccf25.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the brain area, specificially highlighting the brain region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urchin.ccf25.grey.set_visibility(True)\n",
    "urchin.ccf25.grey.set_material('transparent-unlit')\n",
    "urchin.ccf25.grey.set_color([0,0,0])\n",
    "urchin.ccf25.grey.set_alpha(0.1)\n",
    "area_list = urchin.ccf25.get_areas([\"VISp\", \"PTLp\", \"VISam\", \"VISpm\"])\n",
    "urchin.ccf25.set_visibilities(area_list, True)\n",
    "urchin.ccf25.set_materials(area_list,'transparent-unlit')\n",
    "urchin.ccf25.set_colors(area_list,[[0,0,0],[0,0,0],[0,0,0],[0,0,0]])\n",
    "urchin.ccf25.set_alphas(area_list,0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the graph that is attatched to the brain view in Urchin:\n",
    "For this one we will use a separate graph object, so that changing the slider in the graphs above will not affect the neurons in our brain view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urchin_graph = urchin.ui.interactive_plot()\n",
    "urchin_graph.avg_and_bin(st_samp, sc, event_start, event_ids, window_start_sec=0.1, event_duration_sec = 0.3, window_end_sec=0.2, sample= True)\n",
    "urchin_graph.avg_data = np.delete(urchin_graph.avg_data, 88, axis=0) #This line is specific for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urchin_graph.plot_stim_view_interactive_graph(locations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urchin-examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
