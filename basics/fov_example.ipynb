{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage for urchin.fov\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/VirtualBrainLab/urchin-examples/blob/main/basics/fov_example.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Urchin\n",
    "\n",
    "Urchin is a Python package stored on PyPI, the following code needs to be run the first time you use Urchin in a Python environment. \n",
    "\n",
    "Urchin's full documentation can be found [on our website](https://virtualbrainlab.org/urchin/installation_and_use.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing urchin\n",
    "!pip install oursin -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Urchin and open the renderer webpage \n",
    "\n",
    "By default Urchin opens the 3D renderer in a webpage. Make sure pop-ups are enabled, or the page won't open properly. You can also open the renderer site yourself by replacing [ID here] with the ID that is output by the call to `.setup()` at https://data.virtualbrainlab.org/Urchin/?ID=[ID here]\n",
    "\n",
    "Note that Urchin communicates to the renderer webpage through an internet connection, we don't currently support offline use (we hope to add support in the future)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries:\n",
    "import oursin as urchin\n",
    "urchin.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOV tutorial below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Viewing a single FOV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov=urchin.FOV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Image for FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp='/mnt/c/Users/damao/Documents/spring2023/vbl/FOV_00/mpciMeanImage.images.npy' # Replace with your texture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov.set_texture(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Position FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices= [[8.18, 6.97, 0.93],  # CCF coordiantes of the 4 corners for a fov,\n",
    "        [8.21, 7.56, 0.87],     # roughly in the visual cortex \n",
    "        [7.62, 6.97, 0.76],\n",
    "        [7.64, 7.56, 0.70]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov.set_position(vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = mri2ccf('<input file path>/mpciROIs.mlapdv_estimate.npy','<output directory>')\n",
    "# Alternatively, we provide helper functions to load coordinates from files\n",
    "# and transform into CCF space. See mri2ccf() for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Offset for FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov.set_offset(0.5)  # Move up towards brain surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Brain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urchin.ccf.load_beryl()  # View FOV relative to brain model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Batch processing FOVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oursin as urchin\n",
    "urchin.setup(standalone=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps=['/mnt/c/Users/damao/Documents/spring2023/vbl/FOV_00/mpciMeanImage.images.npy',\n",
    "    '/mnt/c/Users/damao/Documents/spring2023/vbl/FOVDefaultTexture.png'] # Replace with your texture data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create FOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 FOVs\n",
    "fovs=urchin.fov.create(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Image for FOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set textures for the 2 FOVs\n",
    "urchin.fov.set_texture(fovs,fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Position FOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCF coordiantes of the 4 corners for two fovs\n",
    "vertices1= [[8.18, 6.97, 0.93],  \n",
    "        [8.21, 7.56, 0.87], \n",
    "        [7.62, 6.97, 0.76],\n",
    "        [7.64, 7.56, 0.70]] \n",
    "        \n",
    "vertices2=[[9.74, 8.14, 1.78],\n",
    "       [9.71, 8.73, 1.85],\n",
    "       [9.26 , 8.14, 1.39],\n",
    "       [9.24, 8.73, 1.44]]\n",
    "\n",
    "# Or read from a file; see mri2ccf() for more details.\n",
    "vertices = mri2ccf('<input file path>/mpciROIs.mlapdv_estimate.npy','<output directory>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urchin.fov.set_position(fov,[vertices1,vertices2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Offset of FOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urchin.fov.set_offset(fov,[0.5,0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Brain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "urchin.ccf.load_beryl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete FOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urchin.fov.delete(fovs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.73818762, 8.14252654, 1.77515527],\n",
       "       [9.70847637, 8.72829154, 1.8494334 ],\n",
       "       [9.2611688 , 8.14252654, 1.3904818 ],\n",
       "       [9.24259926, 8.72829154, 1.43690564]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bregma_ML,bregma_AP,bregma_DV = 5.7,5.4,0.33\n",
    "\n",
    "def mri2ccf(root,saveroot,axis_orders=[0,1,2],MLrev=False,APrev=True,DVrev=True):\n",
    "    \"\"\"Convert coordinates from MRI transform to CCF space\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    root: str\n",
    "        Input file path to read coordiantes from\n",
    "    saveroot: str\n",
    "        Folder to save transformed coordinates to\n",
    "    axis_orders: list of three ints\n",
    "        Specifies the order of ML, AP, DV axes in input data.\n",
    "        Example: [0,2,1] means that column 0 is ML, column 2 is AP, and column 1 is DV.\n",
    "    MLrev, APrev, DVrev: bool\n",
    "        Specifies if any axis has a different direction than the CCF space.\n",
    "        Example: if MLrev is set to True then the ML axis values will be multiply by -1.\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    coords: list of lists of three\n",
    "        Coordinates in CCF space.\n",
    "    \"\"\"\n",
    "    MLax,APax,DVax=axis_orders\n",
    "    MLrev=-1 if MLrev else 1\n",
    "    APrev=-1 if APrev else 1\n",
    "    DVrev=-1 if DVrev else 1\n",
    "\n",
    "    fovcoords = np.load(root) # Will change this later\n",
    "\n",
    "    fovcoords[:,:, 0] = MLrev*fovcoords[:,:, MLax]+bregma_ML\n",
    "    fovcoords[:,:, 1] = APrev*fovcoords[:,:, APax]+bregma_AP\n",
    "    fovcoords[:,:, 2] = DVrev*fovcoords[:,:, DVax]+ bregma_DV\n",
    "    coords=np.array([fovcoords[0,0],fovcoords[0,-1],fovcoords[-1,0],fovcoords[-1,-1]])\n",
    "    np.save(saveroot+\"FOVcoordinates.bytes\",coords)\n",
    "    print(\"Coordinates:\")\n",
    "    print(coords)\n",
    "    print(f\"AP len:{fovcoords[0,0][0]-fovcoords[-1,0][0]}\")\n",
    "    print(f\"ML len:{fovcoords[0,0][0]-fovcoords[-1,0][1]}\")\n",
    "    print(f\"DV len:{fovcoords[0,0][2]-fovcoords[-1,0][2]}\")\n",
    "    print(\"\\n\")\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code for future uses\n",
    "def save_roi_sizes(root,saveroot):\n",
    "    # T x N\n",
    "    mpci_ROIActivityDeconvolved=np.load(root+'/mpci.ROIActivityDeconvolved.npy')\n",
    "    sizes=mpci_ROIActivityDeconvolved[:num_timepoints,:num_neurons]\n",
    "    print(\"Saving ROI sizes. \\nSample data:\\n\")\n",
    "    for x in sizes[:5,:3]:\n",
    "        print(f\"{x},\")\n",
    "    writebytes(sizes,saveroot,\"ROIsizes.bytes\")\n",
    "    \n",
    "    \n",
    "def save_roi_coords(root,saveroot):\n",
    "    mpciROIs_mlapdv_estimate=np.load(root+'/mpciROIs.mlapdv_estimate.npy')\n",
    "    positions = mpciROIs_mlapdv_estimate[:num_neurons]\n",
    "    # adjust from bregma to CCF coordinates\n",
    "    # ML, AP, DV\n",
    "    ccfpositions=positions\n",
    "    ccfpositions[:, 0] = ccfpositions[:, 0]+bregma_ML\n",
    "    ccfpositions[:, 1] = -ccfpositions[:, 1]+bregma_AP\n",
    "    ccfpositions[:, 2] = -ccfpositions[:, 2] + bregma_DV\n",
    "    # adjusted positions\n",
    "    print(\"Saving ROI positions. \\nSample data:\\n\")\n",
    "    for x in ccfpositions[:3]:\n",
    "        print(f\"new Vector3({x[0]:.2f}f,{x[1]:.2f}f,{x[2]:.2f}f),\")\n",
    "    writebytes(positions,saveroot,\"ROIpositions.bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.5090502e-04,  2.5543182e+00,  3.5800919e-02,  2.5044539e+00,\n",
       "        1.0372544e-06,  1.9718944e+00,  4.7638555e+25,  2.5533898e+00,\n",
       "       -4.0475193e-19,  2.5227590e+00,  4.3603449e+35,  1.9811791e+00,\n",
       "       -8.8965520e+25,  2.5394113e+00,  3.5800919e-02,  2.5044539e+00,\n",
       "       -1.9193430e+15,  1.9238101e+00, -1.9007298e+34,  2.5388310e+00,\n",
       "       -4.0475196e-19,  2.5227590e+00, -5.6065710e+02,  1.9296131e+00],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('/mnt/c/Users/damao/Documents/spring2023/vbl/urchin-dev/FOV_01/FOVcoordinates.bytes','rb') as f:\n",
    "    y=bytes(f.read())\n",
    "arr=np.frombuffer(y,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Configurations (for later)\"\"\"\n",
    "AP_MIN=-5.6\n",
    "AP_MAX=7.5\n",
    "DV_MIN=-4\n",
    "DV_MAX=4\n",
    "ML_MIN=-4.8\n",
    "ML_MAX=6.6\n",
    "\n",
    "num_neurons=500\n",
    "num_timepoints=10000\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
